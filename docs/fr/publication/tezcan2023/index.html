<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: 28 novembre 2025 --><html lang=fr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.e31ab33532f2f8d03ad5eb2f8c9e7b33.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Hugo Weissbart"><meta name=description content="This study addresses a fundamental aspect of human speech processing: namely, how acoustic and linguistic features interact during comprehension."><link rel=alternate hreflang=en href=https://hugoweissbart.com/publication/tezcan2023/><link rel=alternate hreflang=fr href=https://hugoweissbart.com/fr/publication/tezcan2023/><link rel=canonical href=https://hugoweissbart.com/fr/publication/tezcan2023/><link rel=manifest href=/fr/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hucc679a67ce0ba819370fc3906c9c7b25_53177_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hucc679a67ce0ba819370fc3906c9c7b25_53177_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://hugoweissbart.com/media/icon_hucc679a67ce0ba819370fc3906c9c7b25_53177_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content><meta property="og:url" content="https://hugoweissbart.com/fr/publication/tezcan2023/"><meta property="og:title" content="A tradeoff between acoustic and linguistic feature encoding in spoken language comprehension | "><meta property="og:description" content="This study addresses a fundamental aspect of human speech processing: namely, how acoustic and linguistic features interact during comprehension."><meta property="og:image" content="https://hugoweissbart.com/media/icon_hucc679a67ce0ba819370fc3906c9c7b25_53177_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="fr"><meta property="article:published_time" content="2017-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-07T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://hugoweissbart.com/fr/publication/tezcan2023/"},"headline":"A tradeoff between acoustic and linguistic feature encoding in spoken language comprehension","datePublished":"2017-01-01T00:00:00Z","dateModified":"2023-07-07T00:00:00Z","author":{"@type":"Person","name":"Filiz Tezcan"},"publisher":{"@type":"Organization","name":"","logo":{"@type":"ImageObject","url":"https://hugoweissbart.com/media/icon_hucc679a67ce0ba819370fc3906c9c7b25_53177_192x192_fill_lanczos_center_3.png"}},"description":"This study addresses a fundamental aspect of human speech processing: namely, how acoustic and linguistic features interact during comprehension."}</script><title>A tradeoff between acoustic and linguistic feature encoding in spoken language comprehension |</title><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token":"33f2bbad376e41c3bda0eab93fd9c1d8"}'></script></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=c08d0efab8b126d11b8b9102b4e82716><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Rechercher</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Fermer><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Recherche... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Recherche...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/fr/></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Ouvrir la barre de navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/fr/></a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/fr/#about><span>Accueil</span></a></li><li class=nav-item><a class=nav-link href=/fr/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/fr/#talks><span>Presentations</span></a></li><li class=nav-item><a class=nav-link href=/fr/tutorials/><span>Tutos</span></a></li><li class=nav-item><a class=nav-link href=/fr/#contact><span>Me contacter</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Rechercher><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Préférences d'affichage"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Clair</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Sombre</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatique</span></a></div></li><li class="nav-item dropdown i18n-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label=Langues><i class="fas fa-globe mr-1" aria-hidden=true></i></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>Français</span></div><a class=dropdown-item href=https://hugoweissbart.com/publication/tezcan2023/><span>English</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>A tradeoff between acoustic and linguistic feature encoding in spoken language comprehension</h1><div class=article-metadata><div><span>Filiz Tezcan</span>, <span>Hugo Weissbart</span>, <span>Andrea E. Martin</span></div><span class=article-date>juillet, 2023</span></div><div class="btn-links mb-3"><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/fr/publication/tezcan2023/cite.bib>Citation</a>
<a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.7554/eLife.82386 target=_blank rel=noopener>DOI</a></div></div><div class=article-container><h3>Résumé</h3><p class=pub-abstract>When we comprehend language from speech, the phase of the neural response aligns with particular features of the speech input, resulting in a phenomenon referred to as neural tracking. In recent years, a large body of work has demonstrated the tracking of the acoustic envelope and abstract linguistic units at the phoneme and word levels, and beyond. However, the degree to which speech tracking is driven by acoustic edges of the signal, or by internally-generated linguistic units, or by the interplay of both, remains contentious. In this study, we used naturalistic story-listening to investigate (1) whether phoneme-level features are tracked over and above acoustic edges, (2) whether word entropy, which can reflect sentence- and discourse-level constraints, impacted the encoding of acoustic and phoneme-level features, and (3) whether the tracking of acoustic edges was enhanced or suppressed during comprehension of a first language (Dutch) compared to a statistically familiar but uncomprehended language (French). We first show that encoding models with phoneme-level linguistic features, in addition to acoustic features, uncovered an increased neural tracking response; this signal was further amplified in a comprehended language, putatively reflecting the transformation of acoustic features into internally generated phoneme-level representations. Phonemes were tracked more strongly in a comprehended language, suggesting that language comprehension functions as a neural filter over acoustic edges of the speech signal as it transforms sensory signals into abstract linguistic units. We then show that word entropy enhances neural tracking of both acoustic and phonemic features when sentence- and discourse-context are less constraining. When language was not comprehended, acoustic features, but not phonemic ones, were more strongly modulated, but in contrast, when a native language is comprehended, phoneme features are more strongly modulated. Taken together, our findings highlight the flexible modulation of acoustic, and phonemic features by sentence and discourse-level constraint in language comprehension, and document the neural transformation from speech perception to language comprehension, consistent with an account of language processing as a neural filter from sensory to abstract representations.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/fr/publication/#2>2</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">eLife</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/fr/tag/meg/>MEG</a>
<a class="badge badge-light" href=/fr/tag/speech/>Speech</a>
<a class="badge badge-light" href=/fr/tag/trf/>TRF</a></div><div class=share-box><ul class=share></ul></div><div class="media author-card content-widget-hr"><a href=https://hugoweissbart.com/><img class="avatar mr-3 avatar-circle" src=/fr/authors/hugo/avatar_hucc679a67ce0ba819370fc3906c9c7b25_53177_270x270_fill_lanczos_center_3.png alt="Hugo Weissbart"></a><div class=media-body><h5 class=card-title><a href=https://hugoweissbart.com/>Hugo Weissbart</a></h5><h6 class=card-subtitle>Postdoctoral researcher</h6><p class=card-text>Focusing in the neurobiology of language comprehension, from a predictive processing perspective.</p><ul class=network-icon aria-hidden=true><li><a href=/fr/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://orcid.org/0000-0003-2820-3865 target=_blank rel=noopener><i class="ai ai-orcid"></i></a></li><li><a href=https://www.researchgate.net/profile/Hugo_Weissbart target=_blank rel=noopener><i class="ai ai-researchgate"></i></a></li><li><a href="https://scholar.google.pl/citations?hl=en&amp;user=Q55ttB0AAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/Hugo-W target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/hugo-weissbart target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/fr/media/resume.pdf><i class="ai ai-cv"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">Licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Publié avec <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — le générateur <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>libre</a> de site web gratuit permetant aux créateurs de s&rsquo;épanouir.</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/fr/js/wowchemy.min.b0195d3d94bd2cb150f4c5703104aa67.js></script>
<script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Citation</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copier</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Télécharger</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script></body></html>