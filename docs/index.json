[{"authors":null,"categories":null,"content":"I am a postdoctoral researcher in the the Language and Computation in Neural System lab at the Donders Intitute, Nijmegen. My research focuses on the predictive aspect of neural computation leading to comprehension of speech. This encompasses the questions of how the brain produces hierarchical linguistic representations in a predictive fashion and how cortical oscillations maintain and coordinate those representations. To this end, I rely mostly on M/EEG analysis with naturalistic stimuli and computational modelling.\n","date":1728864e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1728864e3,"objectID":"6230ca06140409f50430156701677067","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a postdoctoral researcher in the the Language and Computation in Neural System lab at the Donders Intitute, Nijmegen. My research focuses on the predictive aspect of neural computation leading to comprehension of speech.","tags":null,"title":"Hugo Weissbart","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6c34a4873cd166f386563d9bd5fa8a4","permalink":"https://hugoweissbart.com/draft/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/draft/skills/","section":"draft","summary":"","tags":null,"title":"Skills","type":"draft"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"561120995e3325ebdadc6d8e56d79c3e","permalink":"https://hugoweissbart.com/draft/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/draft/accomplishments/","section":"draft","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"draft"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4fbcae97306bf7fd8bef4489ed9717a9","permalink":"https://hugoweissbart.com/draft/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/draft/projects/","section":"draft","summary":"","tags":null,"title":"Projects","type":"draft"},{"authors":null,"categories":null,"content":" Browse all publications.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"29a5e07ce127ac812d7669c8e7b299e1","permalink":"https://hugoweissbart.com/draft/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/draft/publications/","section":"draft","summary":"Browse all publications.","tags":null,"title":"Recent Publications","type":"draft"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f34433162bdbaa5a363d3bab888f7ab2","permalink":"https://hugoweissbart.com/draft/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/draft/tags/","section":"draft","summary":"","tags":null,"title":"Keywords","type":"draft"},{"authors":["Hugo Weissbart","Andrea E. Martin"],"categories":null,"content":" ","date":1728864e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728864e3,"objectID":"30f94f6e1c59d45f6dfdb9df341755a2","permalink":"https://hugoweissbart.com/publication/weissbart_natcomms2024/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/publication/weissbart_natcomms2024/","section":"publication","summary":"In this study we combine continuous MEG recording and forward modelling (temporal response functions) to measure phase-amplitude coupling evoked by distinct linguistic features in spoken language comprehension. We show that both structural and statistical language knowledge jointly shape neural dynamics.","tags":["MEG","PAC","Syntax","TRF","Phase-Amplitude coupling"],"title":"The structure and statistics of language jointly shape cross-frequency neural dynamics during spoken language comprehension","type":"publication"},{"authors":["Hugo Weissbart","Andrea E. Martin"],"categories":null,"content":" ","date":1696550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696550400,"objectID":"21ae1a74d9a70322586002b4f2758175","permalink":"https://hugoweissbart.com/publication/weissbart_preprint2023/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/publication/weissbart_preprint2023/","section":"publication","summary":"...","tags":["MEG","Speech","Predictive Processing","TRF","Phase-Amplitude coupling"],"title":"The Structure and Statistics of Language jointly shape Cross-frequency Dynamics during Spoken Language Comprehension","type":"publication"},{"authors":["Cas Coopmans","Anna Mai","Sophie Slaats","Hugo Weissbart","Andrea E. Martin"],"categories":null,"content":"","date":1694390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694390400,"objectID":"1d2063728af0f647d1afd73cc1eb76ea","permalink":"https://hugoweissbart.com/publication/nat2023/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/nat2023/","section":"publication","summary":"In their timely Perspective article (Kazanina, N. \u0026 Tavano, A. What neural oscillations can and cannot do for syntactic structure building. Nat. Rev. Neurosci. 24, 113–128 (2023))1, Kazanina and Tavano argue that neural oscillations cannot linearly chunk (or segment) speech into syntactic constituents because constituents are defined in terms of hierarchical relations. Instead, they propose that oscillations could support syntactic structure building (SSB) through ‘multi-scale integration’ of hierarchically organized constituents. We agree with their arguments against the utility of chunking for SSB. However, the dichotomy between ‘oscillations for chunking’ and ‘oscillations for integration’ does not accurately represent the literature: the integratory role of oscillations is well-accepted2,3, and chunking is not a candidate model of SSB. Here, we show that recent work on oscillations and syntax4,5 does not assume chunking and we identify principal challenges for the integration proposal put forward by Kazanina and Tavano. ","tags":["syntax","cortical oscillations"],"title":"What oscillations can do for syntax depends on your theory of structure building","type":"publication"},{"authors":["Filiz Tezcan","Hugo Weissbart","Andrea E. Martin"],"categories":null,"content":"","date":1688688e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688688e3,"objectID":"c08d0efab8b126d11b8b9102b4e82716","permalink":"https://hugoweissbart.com/publication/tezcan2023/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/tezcan2023/","section":"publication","summary":"This study addresses a fundamental aspect of human speech processing: namely, how acoustic and linguistic features interact during comprehension.","tags":["MEG","Speech","TRF"],"title":"A tradeoff between acoustic and linguistic feature encoding in spoken language comprehension","type":"publication"},{"authors":["Sophie Slaats","Hugo Weissbart","Andrea E. Martin"],"categories":null,"content":"","date":1687910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687910400,"objectID":"da62bbb58bbdf9405fe716d84cb37b45","permalink":"https://hugoweissbart.com/publication/slaats2023/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/slaats2023/","section":"publication","summary":"Human language is unprecedented in its combinatorial capacity; we are capable of producing and understanding sentences we have never heard before. Although the mechanisms underlying this capacity have been described in formal linguistics and cognitive science, how they are implemented in the brain remains to a large extent unknown. A large body of earlier work from the cognitive neuroscientific literature implies a role for delta-band neural activity in the representation of linguistic structure and meaning. In this work, we combine these insights and techniques with findings from psycholinguistics to show that meaning is more than the sum of its parts; the delta-band MEG signal differentially reflects lexical information inside and outside sentence structures.","tags":["EEG","Speech","TRF"],"title":"Delta-Band Neural Responses to Individual Words Are Modulated by Sentence Processing","type":"publication"},{"authors":["Ioanna Zioga","Hugo Weissbart","Ashley G. Lewis","Saskia Haegens","Andrea E. Martin"],"categories":null,"content":"","date":1684281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684281600,"objectID":"c48d843e3c846913a139f6a298667463","permalink":"https://hugoweissbart.com/publication/zioga2023/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/zioga2023/","section":"publication","summary":"It remains unclear whether the proposed functional role of α and β oscillations in perceptual and motor function is generalizable to higher-level cognitive processes, such as spoken language comprehension. We found that syntactic features predict α and β power in language-related regions beyond low-level linguistic features when listening to naturalistic speech in a known language. We offer experimental findings that integrate a neuroscientific framework on the role of brain oscillations as “building blocks” with spoken language comprehension. This supports the view of a domain-general role of oscillations across the hierarchy of cognitive functions, from low-level sensory operations to abstract linguistic processes.","tags":["MEG","beta oscillations","dependency parsing","TRF"],"title":"Naturalistic Spoken Language Comprehension Is Supported by Alpha and Beta Oscillations","type":"publication"},{"authors":["Miklaj Kegler","Hugo Weissbart","Tobias Reichenbach"],"categories":null,"content":"","date":1658016e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658016e3,"objectID":"0aa3a0ef2115b6e7c158c1dd845f3485","permalink":"https://hugoweissbart.com/publication/kegler2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/kegler2022/","section":"publication","summary":"Spoken language comprehension requires rapid and continuous integration of information, from lower-level acoustic to higher-level linguistic features. Much of this processing occurs in the cerebral cortex. Its neural activity exhibits, for instance, correlates of predictive processing, emerging at delays of a few 100 ms. However, the auditory pathways are also characterized by extensive feedback loops from higher-level cortical areas to lower-level ones as well as to subcortical structures. Early neural activity can therefore be influenced by higher-level cognitive processes, but it remains unclear whether such feedback contributes to linguistic processing. Here, we investigated early speech-evoked neural activity that emerges at the fundamental frequency. We analyzed EEG recordings obtained when subjects listened to a story read by a single speaker. We identified a response tracking the speaker's fundamental frequency that occurred at a delay of 11 ms, while another response elicited by the high-frequency modulation of the envelope of higher harmonics exhibited a larger magnitude and longer latency of about 18 ms with an additional significant component at around 40 ms. Notably, while the earlier components of the response likely originate from the subcortical structures, the latter presumably involves contributions from cortical regions. Subsequently, we determined the magnitude of these early neural responses for each individual word in the story. We then quantified the context-independent frequency of each word and used a language model to compute context-dependent word surprisal and precision. The word surprisal represented how predictable a word is, given the previous context, and the word precision reflected the confidence about predicting the next word from the past context. We found that the word-level neural responses at the fundamental frequency were predominantly influenced by the acoustic features: the average fundamental frequency and its variability. Amongst the linguistic features, only context-independent word frequency showed a weak but significant modulation of the neural response to the high-frequency envelope modulation. Our results show that the early neural response at the fundamental frequency is already influenced by acoustic as well as linguistic information, suggesting top-down modulation of this neural response. ","tags":["brainstem recording","Backward model","TRF","cortical tracking"],"title":"The neural response at the fundamental frequency of speech is modulated by word-level acoustic and linguistic information","type":"publication"},{"authors":["Hugo Weissbart"],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1579006800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579006800,"objectID":"9bbb843b5eb5c06ca9cb3ba76b4eb07c","permalink":"https://hugoweissbart.com/talk/leuven/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/leuven/","section":"talk","summary":"A presentation and summary of my main PhD results","tags":["EEG","TRF","Predictive Processing","Syntax"],"title":"Cortical tracking of linguistic features in continuous EEG","type":"talk"},{"authors":["Hugo Weissbart","Katerina D. Kandylaki","Tobias Reichenbach"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"4325a722e308dec6c74f1b13de2d5f11","permalink":"https://hugoweissbart.com/publication/weissbart_jocn2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/weissbart_jocn2020/","section":"publication","summary":"Word surprisal and word entropy, derived from a recurrent neural networl for language modelling, are represented in EEG signals in several freuqency bands. The neural encoding is quantified using temporal response functions with continuous EEG recorded during naturalsitic story listening.","tags":["EEG","Speech","Predictive Processing","TRF"],"title":"Cortical Tracking of Surprisal during Continuous Speech Comprehension","type":"publication"},{"authors":["Shabnam Kadir","Hugo Weissbart"],"categories":[],"content":"","date":1574617033,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574617033,"objectID":"65c86b321c53fa2fdebab59a7fb6b9aa","permalink":"https://hugoweissbart.com/publication/modulation_sin/","publishdate":"2020-12-24T18:37:13+01:00","relpermalink":"/publication/modulation_sin/","section":"publication","summary":"Neural activity tracks the envelope of a speech signal at latencies from 50 ms to 300 ms. Modulating this neural tracking through transcranial alternating current stimulation influences speech comprehension. Two important variables that can affect this modulation are the latency and the phase of the stimulation with respect to the sound. While previous studies have found an influence of both variables on speech comprehension, the interaction between both has not yet been measured. We presented 17 subjects with speech in noise coupled with simultaneous transcranial alternating current stimulation. The currents were based on the envelope of the target speech but shifted by different phases, as well as by two temporal delays of 100 ms and 250 ms. We also employed various control stimulations, and assessed the signal-to-noise ratio at which the subject understood half of the speech. We found that, at both latencies, speech comprehension is modulated by the phase of the current stimulation. However, the form of the modulation differed between the two latencies. Phase and latency of neurostimulation have accordingly distinct influences on speech comprehension. The different effects at the latencies of 100 ms and 250 ms hint at distinct neural processes for speech processing.","tags":["EEG","tACS","speech comprehension"],"title":"Modulation of Speech-in-Noise Comprehension Through Transcranial Current Stimulation With the Phase-Shifted Speech Envelope","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://hugoweissbart.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Hugo Weissbart"],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1496322e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496322e3,"objectID":"32caf9514e7781d91f3e26b5ed51f498","permalink":"https://hugoweissbart.com/talk/poster_snl2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/poster_snl2017/","section":"talk","summary":"Poster presented at SNL 2017","tags":["EEG","Predictive Processing","TRF"],"title":"Electrophysiological correlates of statistical features of word sequences in natural spoken language","type":"talk"},{"authors":["Hugo Weissbart"],"categories":["Art"],"content":"SINES - an LSD brain wave and sound art hackathon by AXNS Collective This piece was produced over a two-day brain wave and sound art hackathon in March 2017, organised by AXNS Collective and in collaboration with Imperial College London and Music Hackspace.\nBringing sound artists and neuroscientist together to synthesize sonic atmospheres and music from MEG activity recorded by Dr. Robin Carhart-Harris, Head of Psychedelic Research in the Division of Brain Sciences at Imperial College London. Listen to more on the AXNS collective page.\n","date":1494892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"46cdfebb5fcfdc564594a5d7d12d1d6d","permalink":"https://hugoweissbart.com/post/sines-hackathon/","publishdate":"2017-05-16T00:00:00Z","relpermalink":"/post/sines-hackathon/","section":"post","summary":"This projects encouraged scientists to experiment with innovative and novel analysis techniques with the aim to expand the way scientists usually look at brain wave data.","tags":["EEG","Art"],"title":"SINES - AXNS Collective","type":"post"}]